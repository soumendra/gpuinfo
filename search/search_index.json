{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to GPUInfoNV","text":"<p>GPUInfoNV is a Python library for gathering and managing information about NVIDIA GPUs. It provides functionality to retrieve GPU statistics, check PyTorch availability, and free up GPU resources.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Detect and gather information about NVIDIA GPUs</li> <li>Check PyTorch and CUDA availability</li> <li>Retrieve detailed GPU statistics</li> <li>Free up GPU resources, including process termination and cache clearing</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>You can install GPUInfoNV using pip:</p> <pre><code>pip install gpuinfonv\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Here's a simple example of how to use GPUInfoNV:</p> <pre><code>from gpuinfonv import GPUInfo\n\n# Create a GPUInfo instance\ngpu_info = GPUInfo()\n\n# Print information about all detected GPUs\ngpu_info.print_gpu_info()\n\n# Free up GPU resources\ngpu_info.free_up_gpu(0)  # Free up GPU 0\n</code></pre> <p>For more detailed information, check out the Usage Guide and API Reference.</p>"},{"location":"api_reference/","title":"API Reference","text":""},{"location":"api_reference/#gpuinfonv","title":"GPUInfonv","text":"<pre><code>class GPUInfo(BaseModel)\n</code></pre> <p>A class to represent information about available GPUs and manage GPU resources.</p>"},{"location":"api_reference/#methods","title":"Methods","text":""},{"location":"api_reference/#__init__data","title":"<code>__init__(**data)</code>","text":"<p>Initialize the GPUInfo object and gather initial GPU information.</p>"},{"location":"api_reference/#initialize_gpu_info","title":"<code>initialize_gpu_info()</code>","text":"<p>Initialize GPU information by detecting GPUs and checking PyTorch availability.</p>"},{"location":"api_reference/#get_gpu_stats-listgpustat","title":"<code>get_gpu_stats() -&gt; List[GPUStat]</code>","text":"<p>Retrieve current statistics for all detected GPUs.</p>"},{"location":"api_reference/#check_torch_availability","title":"<code>check_torch_availability()</code>","text":"<p>Check if PyTorch is installed and if CUDA is available for PyTorch.</p>"},{"location":"api_reference/#print_gpu_info","title":"<code>print_gpu_info()</code>","text":"<p>Print detailed information about all detected GPUs and PyTorch availability.</p>"},{"location":"api_reference/#free_up_gpugpu_index-int-0-terminate_processes-bool-true-clear_cache-bool-true-exempt_processes-liststr-default_exempt_processes","title":"<code>free_up_gpu(gpu_index: int = 0, terminate_processes: bool = True, clear_cache: bool = True, exempt_processes: List[str] = DEFAULT_EXEMPT_PROCESSES)</code>","text":"<p>Attempt to free up the specified GPU from any ongoing operations and bring it to a clean idle state.</p> <p>Arguments: - <code>gpu_index</code> (int): The index of the GPU to free up. Defaults to 0. - <code>terminate_processes</code> (bool): Whether to terminate CUDA processes. Defaults to True. - <code>clear_cache</code> (bool): Whether to clear the GPU cache. Defaults to True. - <code>exempt_processes</code> (List[str]): List of process names to exempt from termination. Defaults to DEFAULT_EXEMPT_PROCESSES.</p>"},{"location":"api_reference/#gpustat","title":"GPUStat","text":"<pre><code>class GPUStat(BaseModel)\n</code></pre> <p>A class to represent statistics for a single GPU.</p>"},{"location":"api_reference/#attributes","title":"Attributes","text":"<ul> <li><code>index</code> (int): The index of the GPU.</li> <li><code>name</code> (str): The name of the GPU.</li> <li><code>total_memory</code> (float): Total memory of the GPU in GB.</li> <li><code>used_memory</code> (float): Used memory of the GPU in GB.</li> <li><code>free_memory</code> (float): Free memory of the GPU in GB.</li> <li><code>temperature</code> (float): Temperature of the GPU in Celsius.</li> <li><code>gpu_utilization</code> (float): GPU utilization as a percentage.</li> <li><code>memory_utilization</code> (float): Memory utilization as a percentage.</li> <li><code>fan_speed</code> (Optional[float]): Fan speed as a percentage, if available.</li> </ul>"},{"location":"api_reference/#constants","title":"Constants","text":""},{"location":"api_reference/#default_exempt_processes","title":"<code>DEFAULT_EXEMPT_PROCESSES</code>","text":"<p>A list of process names that are exempt from termination by default when using the <code>free_up_gpu</code> method.</p> <p>Default value: <code>[\"/usr/lib/xorg/Xorg\", \"/usr/bin/gnome-shell\", \"warp-terminal\"]</code></p>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide provides examples of how to use the GPUInfoNV library effectively.</p>"},{"location":"usage/#basic-usage","title":"Basic Usage","text":""},{"location":"usage/#initializing-gpuinfonv","title":"Initializing GPUInfonv","text":"<pre><code>from gpuinfonv import GPUInfo\n\n# Create a GPUInfo instance\ngpu_info = GPUInfo()\n</code></pre>"},{"location":"usage/#printing-gpu-information","title":"Printing GPU Information","text":"<pre><code># Print information about all detected GPUs\ngpu_info.print_gpu_info()\n</code></pre>"},{"location":"usage/#freeing-up-gpu-resources","title":"Freeing Up GPU Resources","text":"<pre><code># Free up GPU 0 (terminate processes and clear cache)\ngpu_info.free_up_gpu(0)\n\n# Only clear cache on GPU 1 without terminating processes\ngpu_info.free_up_gpu(1, terminate_processes=False, clear_cache=True)\n\n# Only terminate processes on GPU 2 without clearing cache\ngpu_info.free_up_gpu(2, terminate_processes=True, clear_cache=False)\n</code></pre>"},{"location":"usage/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/#customizing-exempt-processes","title":"Customizing Exempt Processes","text":"<p>You can customize the list of processes that are exempt from termination:</p> <pre><code>from gpuinfonv import GPUInfo, DEFAULT_EXEMPT_PROCESSES\n\ngpu_info = GPUInfo()\n\n# Add a custom process to the default exempt list\ncustom_exempt = DEFAULT_EXEMPT_PROCESSES + [\"my-custom-process\"]\ngpu_info.free_up_gpu(0, exempt_processes=custom_exempt)\n\n# Use a completely custom list of exempt processes\ngpu_info.free_up_gpu(0, exempt_processes=[\"process1\", \"process2\"])\n\n# Terminate all processes (use with caution!)\ngpu_info.free_up_gpu(0, exempt_processes=[])\n</code></pre>"},{"location":"usage/#retrieving-gpu-statistics","title":"Retrieving GPU Statistics","text":"<p>You can get detailed statistics for each GPU:</p> <pre><code>gpu_stats = gpu_info.get_gpu_stats()\nfor stat in gpu_stats:\n    print(f\"GPU {stat.index}:\")\n    print(f\"  Name: {stat.name}\")\n    print(f\"  Total Memory: {stat.total_memory:.2f} GB\")\n    print(f\"  Used Memory: {stat.used_memory:.2f} GB\")\n    print(f\"  Free Memory: {stat.free_memory:.2f} GB\")\n    print(f\"  Temperature: {stat.temperature}\u00b0C\")\n    print(f\"  GPU Utilization: {stat.gpu_utilization}%\")\n    print(f\"  Memory Utilization: {stat.memory_utilization}%\")\n    if stat.fan_speed is not None:\n        print(f\"  Fan Speed: {stat.fan_speed}%\")\n    print()\n</code></pre> <p>This will give you a detailed overview of each GPU's current state and usage.</p>"}]}